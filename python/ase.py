# Container for the Population by Age Sex Ethnicity module. See the Estimates-Program
# wiki page for more details:
# https://github.com/SANDAG/Estimates-Program/wiki/Population-by-Age-Sex-Ethnicity

import ipfn
import iteround
import functools
import numpy as np
import pandas as pd
import sqlalchemy as sql

import python.utils as utils


_AGE_MAPPING = {
    "Under 5": {"min": 0, "max": 4},
    "5 to 9": {"min": 5, "max": 9},
    "10 to 14": {"min": 10, "max": 14},
    "15 to 17": {"min": 15, "max": 17},
    "18 and 19": {"min": 18, "max": 19},
    "20 to 24": {"min": 20, "max": 24},
    "25 to 29": {"min": 25, "max": 29},
    "30 to 34": {"min": 30, "max": 34},
    "35 to 39": {"min": 35, "max": 39},
    "40 to 44": {"min": 40, "max": 44},
    "45 to 49": {"min": 45, "max": 49},
    "50 to 54": {"min": 50, "max": 54},
    "55 to 59": {"min": 55, "max": 59},
    "60 and 61": {"min": 60, "max": 61},
    "62 to 64": {"min": 62, "max": 64},
    "65 to 69": {"min": 65, "max": 69},
    "70 to 74": {"min": 70, "max": 74},
    "75 to 79": {"min": 75, "max": 79},
    "80 to 84": {"min": 80, "max": 84},
    "85 and Older": {"min": 85, "max": 100},
}


def run_ase(year: int) -> None:
    """Orchestrator function for age/sex/ethnicity population by type.

    Creates regional age/sex/ethnicity controls by population type. Then
    calculates MGRA level age/sex/ethnicity population by type using these
    regional controls, synthesized census tract level seed data, and MGRA
    level population by type generated by the Population by Type module.
    Results are inserted into the production database along with the regional
    controls.

    Functionality is segmented into functions for code encapsulation:
        _get_controls_inputs - Get regional age/sex/ethnicity controls from
            CA DOF for total population, regional age/sex/ethnicity group
            quarters by type distributions from the 5-year ACS PUMS, and
            regional population by type generated by the Population by Type
            module
        _create_controls - Calculate regional age/sex/ethnicity controls by
            population type
        _insert_controls - Insert regional age/sex/ethnicity controls by
            population type to production database
        _get_seed_inputs - Get 5-year ACS Detailed Tables B010001, B03002, and
            B01001(B-I)
        _create_seed - Calculate census tract level age/sex/ethnicity seed
            data for total population
        _get_ase_inputs - Get MGRA population by type generated by the
            Population by Type module, special MGRAs with age/sex restrictions
            by population type, regional age/sex/ethnicity controls by
            population type, and census tract level age/sex/ethnicity seed
            data for total population
        _create_ase - Calculate MGRA level age/sex/ethnicity population by
            population type
        _insert_ase - Insert MGRA level age/sex/ethnicity population by
            population type to production database

    Args:
        year (int): estimates year
    """
    # Calculate regional age/sex/ethnicity controls by population type
    controls_inputs = _get_controls_inputs(year)
    # TODO: validate inputs

    controls_outputs = _create_controls(controls_inputs)
    # TODO: validate outputs

    _insert_controls(controls_outputs)

    # Calculate MGRA age/sex/ethnicity population by population type
    ase_inputs = _get_ase_inputs(year)
    # TODO: validate inputs

    ase_outputs = _create_ase(ase_inputs)
    # TODO: validate outputs

    _insert_ase(year, ase_outputs)


@functools.lru_cache(maxsize=1)
def _get_controls_inputs(year: int) -> dict[str, pd.DataFrame]:
    """Get inputs required to calculate regional age/sex/ethnicity controls."""
    with utils.ESTIMATES_ENGINE.connect() as conn:
        # Get regional age/sex/ethnicity controls for total population
        with open(utils.SQL_FOLDER / "ase/get_region_ase_total.sql") as file:
            region_ase_total = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

        # Get regional age/sex/ethnicity group quarters distributions
        with open(utils.SQL_FOLDER / "ase/get_region_gq_ase_dist.sql") as file:
            region_gq_ase_dist = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

        # Get regional population by type output generated by Estimates program
        with open(utils.SQL_FOLDER / "ase/get_region_pop_type.sql") as file:
            region_pop_type = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

    return {
        "region_ase_total": region_ase_total,
        "region_gq_ase_dist": region_gq_ase_dist,
        "region_pop_type": region_pop_type,
    }


def _create_controls(controls_inputs: dict[str, pd.DataFrame]) -> pd.DataFrame:
    """Create regional age/sex/ethnicity controls by population type."""

    # Load input data into separate variables for cleaner manipulation
    region_ase_total = controls_inputs["region_ase_total"]
    region_gq_ase_dist = controls_inputs["region_gq_ase_dist"]
    region_pop_type = controls_inputs["region_pop_type"]

    # Scale the regional age/sex/ethnicity total controls to the regional population
    region_ase_total["population"] = iteround.saferound(
        region_ase_total["population"].astype(float),
        places=0,
        topline=region_pop_type["value"].sum(),
    )

    # Calculate the group quarters age/sex/ethnicity population
    # Pivot the group quarters age/sex/ethnicity population by type
    # Such that age/sex/ethnicity categories are rows
    # And group quarters population by type are columns
    gq_pop = (
        region_gq_ase_dist.merge(
            right=region_pop_type, left_on="gq_type", right_on="pop_type"
        )
        .assign(value=lambda x: x["value"] * x["distribution"])
        .sort_values(by=["pop_type"])
        .pivot(
            index=["age_group", "sex", "ethnicity"],
            columns="pop_type",
            values="value",
        )
        .sort_index()
    )

    # Create row marginal controls for age/sex/ethnicity categories
    row_crtls = region_ase_total.sort_values(by=["age_group", "sex", "ethnicity"])[
        "population"
    ].to_list()

    # Create column marginal controls for group quarters population by type
    col_crtls = (
        region_pop_type[region_pop_type["pop_type"] != "Household Population"]
        .sort_values(by=["pop_type"])["value"]
        .to_list()
    )

    # Integerize the group quarters age/sex/ethnicity population by type
    region_gq_ase = utils.integerize_2d(
        df=gq_pop,
        row_crtls=row_crtls,
        col_crtls=col_crtls,
        condition="less than",
    )

    # Calculate the household age/sex/ethnicity population as the remainder
    # Return the regional age/sex/ethnicity controls by population type
    return (
        region_ase_total.merge(
            right=region_gq_ase.assign(gq=lambda x: x.sum(axis=1)).reset_index(),
            on=["age_group", "sex", "ethnicity"],
        )
        .assign(hhp=lambda x: x["population"] - x["gq"])
        .drop(columns=["population", "gq"])
        .rename(columns={"hhp": "Household Population"})
        .melt(
            id_vars=["run_id", "year", "age_group", "sex", "ethnicity"],
            var_name="pop_type",
        )
    )


def _insert_controls(controls_outputs: pd.DataFrame) -> None:
    """Insert regional age/sex/ethnicity controls to database."""
    with utils.ESTIMATES_ENGINE.connect() as conn:
        controls_outputs.to_sql(
            name="controls_ase",
            con=conn,
            schema="inputs",
            if_exists="append",
            index=False,
        )


def _get_seed_inputs(year: int) -> dict[str, pd.DataFrame]:
    """Get inputs required to generate census tract age/sex/ethnicity seed data."""
    with utils.ESTIMATES_ENGINE.connect() as conn:
        # Get the Age/Sex B010001 table data
        with open(utils.SQL_FOLDER / "ase/get_B01001.sql") as file:
            b01001 = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "year": year,
                },
            )

        # Get the Ethnicity B03002 table data
        with open(utils.SQL_FOLDER / "ase/get_B03002.sql") as file:
            b03002 = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "year": year,
                },
            )

        # Get Age/Sex/Ethnicity data from B01001(B-I) table data
        with open(utils.SQL_FOLDER / "ase/get_B01001(B-I).sql") as file:
            b01001_b_i = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "year": year,
                },
            )

    return {"b01001": b01001, "b03002": b03002, "b01001_b_i": b01001_b_i}


def _create_seed(seed_inputs: dict[str, pd.DataFrame]) -> pd.DataFrame:
    """Create census tract age/sex/ethnicity seed data."""
    # Create dictionary of DataFrames and their dimensions to be used in IPF
    dimensions = {
        "b01001": {"labels": ["age_group", "sex"], "values": [0, 1]},
        "b03002": {"labels": ["ethnicity"], "values": [2]},
        "b01001_b_i": {
            "labels": ["age_group", "sex", "ethnicity"],
            "values": [0, 1, 2],
        },
    }

    output = []
    # Within each census tract
    for tract in seed_inputs["b01001_b_i"]["tract"].unique():
        # Create inputs to IPF of numpy ndarrays
        ipf_inputs = {}
        for table, metadata in dimensions.items():
            frame = (
                seed_inputs[table][seed_inputs[table]["tract"] == tract]
                .groupby(metadata["labels"])["value"]
                .sum()
            )

            if len(metadata["labels"]) == 1:
                ipf_inputs[table] = frame.to_numpy()
            else:
                ipf_inputs[table] = np.reshape(
                    frame.to_numpy(), tuple(map(len, frame.index.levels))
                )

        # Run IPF
        ipf = ipfn.ipfn.ipfn(
            ipf_inputs["b01001_b_i"],
            aggregates=[ipf_inputs["b01001"], ipf_inputs["b03002"]],
            dimensions=[
                dimensions["b01001"]["values"],
                dimensions["b03002"]["values"],
            ],
            max_iteration=10000,
        )

        # Transform result back to DataFrame
        result = (
            seed_inputs["b01001_b_i"][dimensions["b01001_b_i"]["labels"]]
            .drop_duplicates()
            .sort_values(by=dimensions["b01001_b_i"]["labels"])
            .assign(tract=tract, value=ipf.iteration().flatten())
        )

        # Append to output list
        output.append(result)

    return pd.concat(output, ignore_index=True)


def _get_ase_inputs(year: int) -> dict[str, pd.DataFrame]:
    with utils.ESTIMATES_ENGINE.connect() as conn:
        # Get the MGRA-level population by type data
        with open(utils.SQL_FOLDER / "ase/get_mgra_pop_type.sql") as file:
            mgra_pop_type = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

        # Get special MGRAs for age/sex restrictions
        with open(utils.SQL_FOLDER / "ase/get_special_mgras.sql") as file:
            special_mgras = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "year": year,
                    "mgra_version": utils.MGRA_VERSION,
                },
            )

    controls_ase = _create_controls(
        _get_controls_inputs(year=year)
    )  # TODO: fold into inputs provided and remove lru_cache?
    seed_tracts = _create_seed(_get_seed_inputs(year=year))

    return {
        "mgra_pop_type": mgra_pop_type,
        "special_mgras": special_mgras,
        "controls_ase": controls_ase,
        "seed_tracts": seed_tracts,
    }


def _create_ase(ase_inputs: dict[str, pd.DataFrame]) -> pd.DataFrame:
    """Create MGRA age/sex/ethnicity population by type."""
    # Merge the MGRA-level population by type data with the seed data
    # And provide special MGRA information to apply age/sex restrictions
    seed_mgras = (
        ase_inputs["mgra_pop_type"]
        .merge(right=ase_inputs["seed_tracts"], on="tract", suffixes=("_delete", ""))
        .merge(
            right=ase_inputs["special_mgras"],
            on=["mgra", "pop_type"],
            how="left",
            suffixes=("", "_special"),
        )
        .merge(
            right=pd.DataFrame.from_dict(_AGE_MAPPING, orient="index").reset_index(
                names="age_group"
            ),
            on="age_group",
        )
    )

    # Apply age/sex restrictions
    # Set 0-valued seed data to 1 where special MGRA data exists
    # To allow greater IPF flexibility within restricted categories
    seed_mgras.loc[
        (seed_mgras["value"] == 0)
        & (
            (seed_mgras["sex_special"].notna())
            | (seed_mgras["min_age"].notna())
            | (seed_mgras["max_age"].notna())
        ),
        "value",
    ] = 1

    # Set the MGRA-level seed data to 0 for special MGRAs
    # Where the age/sex restrictions are violated
    # Seed data set to 0 remains 0 in an IPF process
    seed_mgras.loc[
        (seed_mgras["sex"] != seed_mgras["sex_special"])
        & (seed_mgras["sex_special"].notna()),
        "value",
    ] = 0

    seed_mgras.loc[
        (seed_mgras["max"] < seed_mgras["min_age"])
        | (seed_mgras["min"] > seed_mgras["max_age"]),
        "value",
    ] = 0

    # Add the MGRA seed data to the input dictionary of DataFrames
    ase_inputs["seed_mgras"] = seed_mgras

    # Create dictionary of DataFrames and their dimensions to be used in IPF
    dimensions = {
        "controls_ase": {
            "labels": ["pop_type", "age_group", "sex", "ethnicity"],
            "values": [1, 2, 3, 4],
        },
        "mgra_pop_type": {
            "labels": ["mgra", "pop_type"],
            "values": [0, 1],
        },
        "seed_mgras": {
            "labels": ["mgra", "pop_type", "age_group", "sex", "ethnicity"],
            "values": [0, 1, 2, 3, 4],
        },
    }

    # Create inputs to IPF of numpy ndarrays
    ipf_inputs = {}
    for table, metadata in dimensions.items():
        frame = ase_inputs[table].groupby(metadata["labels"])["value"].sum()

        if len(metadata["labels"]) == 1:
            ipf_inputs[table] = frame.to_numpy()
        else:
            ipf_inputs[table] = np.reshape(
                frame.to_numpy(), tuple(map(len, frame.index.levels))
            )

    # Run IPF
    ipf = ipfn.ipfn.ipfn(
        ipf_inputs["seed_mgras"],
        aggregates=[ipf_inputs["controls_ase"], ipf_inputs["mgra_pop_type"]],
        dimensions=[
            dimensions["controls_ase"]["values"],
            dimensions["mgra_pop_type"]["values"],
        ],
        max_iteration=10000,
    )

    # Transform result back to DataFrame
    ipf_result = (
        ase_inputs["seed_mgras"][dimensions["seed_mgras"]["labels"]]
        .drop_duplicates()
        .sort_values(by=dimensions["seed_mgras"]["labels"])
        .assign(value=ipf.iteration().flatten())
    )

    # Integerize the IPF results
    result = []
    # For each population type
    for pop_type in ipf_result["pop_type"].unique():
        # Pivot data such that age/sex/ethnicity are columns
        # And the MGRA population are rows
        population = (
            ipf_result.query("pop_type == @pop_type")
            .sort_values(by=["age_group", "sex", "ethnicity"])
            .pivot(
                index=["mgra"],
                columns=["age_group", "sex", "ethnicity"],
                values="value",
            )
            .sort_index()
        )

        # Create row marginal controls for MGRA population
        row_crtls = (
            ase_inputs["mgra_pop_type"]
            .query("pop_type == @pop_type")
            .sort_values(by=["mgra"])["value"]
            .to_list()
        )

        # Create column marginal controls for age/sex/ethnicity
        col_crtls = (
            ase_inputs["controls_ase"]
            .query("pop_type == @pop_type")
            .sort_values(by=["age_group", "sex", "ethnicity"])["value"]
            .to_list()
        )

        # Integerize the age/sex/ethnicity population
        population = utils.integerize_2d(
            df=population,
            row_crtls=row_crtls,
            col_crtls=col_crtls,
            condition="exact",
        )

        # Append to output list in long-format
        result.append(
            population.melt(ignore_index=False).reset_index().assign(pop_type=pop_type)
        )

    # Return integerized results
    return pd.concat(result, ignore_index=True)


def _insert_ase(year: int, ase_outputs: pd.DataFrame) -> None:
    """Insert age/sex/ethnicity population by type to database."""
    with utils.ESTIMATES_ENGINE.connect() as conn:
        ase_outputs.assign(run_id=utils.RUN_ID, year=year).to_sql(
            name="ase",
            con=conn,
            schema="outputs",
            if_exists="append",
            index=False,
        )
