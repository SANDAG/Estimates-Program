# Container for the Population by Age Sex Ethnicity module. See the Estimates-Program
# wiki page for more details:
# https://github.com/SANDAG/Estimates-Program/wiki/Population-by-Age-Sex-Ethnicity

import ipfn
import functools

import numpy as np
import pandas as pd
import polars as pl
import sqlalchemy as sql

import python.tests as tests
import python.utils as utils


def run_ase(year: int) -> None:
    """Orchestrator function for age/sex/ethnicity population by type.

    Creates regional age/sex/ethnicity controls by population type. Then
    calculates MGRA level age/sex/ethnicity population by type using these
    regional controls, synthesized census tract level seed data, and MGRA
    level population by type generated by the Population by Type module.
    Results are inserted into the production database along with the regional
    controls.

    Functionality is segmented into functions for code encapsulation:
        _get_controls_inputs - Get regional age/sex/ethnicity controls from
            CA DOF for total population, regional age/sex/ethnicity group
            quarters by type distributions from the 5-year ACS PUMS, and
            regional population by type generated by the Population by Type
            module
        _validate_controls_inputs - Validate the controls input data from the
            above function
        _create_controls - Calculate regional age/sex/ethnicity controls by
            population type
        _validate_controls_outputs - Validate the controls output data from
            the above function
        _insert_controls - Insert regional age/sex/ethnicity controls by
            population type to production database
        _get_seed_inputs - Get 5-year ACS Detailed Tables B010001, B03002, and
            B01001(B-I)
        _create_seed - Calculate census tract level age/sex/ethnicity seed
            data for total population
        _get_ase_inputs - Get MGRA population by type generated by the
            Population by Type module, special MGRAs with age/sex restrictions
            by population type, regional age/sex/ethnicity controls by
            population type, and census tract level age/sex/ethnicity seed
            data for total population
        _validate_ase_inputs - Validate the age/sex/ethnicity input data from
            the above function
        _create_ase - Calculate MGRA level age/sex/ethnicity population by
            population type
        _validate_ase_outputs - Validate the age/sex/ethnicity output data from
            the above function
        _insert_ase - Insert MGRA level age/sex/ethnicity population by
            population type to production database

    Args:
        year (int): estimates year
    """
    # Calculate regional age/sex/ethnicity controls by population type
    controls_inputs = _get_controls_inputs(year)
    _validate_controls_inputs(controls_inputs)

    controls_outputs = _create_controls(controls_inputs)
    _validate_controls_outputs(controls_outputs)

    _insert_controls(controls_outputs)

    # Calculate MGRA age/sex/ethnicity population by population type
    ase_inputs = _get_ase_inputs(year)
    _validate_ase_inputs(year, ase_inputs)

    ase_outputs = _create_ase(ase_inputs)
    _validate_ase_outputs(ase_outputs)

    _insert_ase(ase_outputs)


@functools.lru_cache(maxsize=1)
def _get_controls_inputs(year: int) -> dict[str, pd.DataFrame]:
    """Get inputs required to calculate regional age/sex/ethnicity controls."""
    with utils.ESTIMATES_ENGINE.connect() as conn:
        # Get regional age/sex/ethnicity controls for total population
        with open(utils.SQL_FOLDER / "ase/get_region_ase_total.sql") as file:
            region_ase_total = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

        # Get regional age/sex/ethnicity group quarters distributions
        with open(utils.SQL_FOLDER / "ase/get_region_gq_ase_dist.sql") as file:
            region_gq_ase_dist = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

        # Get regional population by type output generated by Estimates program
        with open(utils.SQL_FOLDER / "ase/get_region_pop_type.sql") as file:
            region_pop_type = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

    return {
        "region_ase_total": region_ase_total,
        "region_gq_ase_dist": region_gq_ase_dist,
        "region_pop_type": region_pop_type,
    }


def _validate_controls_inputs(controls_inputs: dict[str, pd.DataFrame]) -> None:
    """Validate the regional age/sex/ethnicity controls input data"""
    tests.validate_data(
        "CA DOF Regional ASE Total Controls",
        controls_inputs["region_ase_total"],
        row_count={"key_columns": {"age_group", "sex", "ethnicity"}},
        negative={},
        null={},
    )
    tests.validate_data(
        "ACS Regional GQ ASE Distribution",
        controls_inputs["region_gq_ase_dist"],
        row_count={"key_columns": {"gq_type", "age_group", "sex", "ethnicity"}},
        negative={},
        null={},
    )
    tests.validate_data(
        "Regional Population by Type Estimates",
        controls_inputs["region_pop_type"],
        row_count={"key_columns": {"pop_type"}},
        negative={},
        null={},
    )


def _create_controls(controls_inputs: dict[str, pd.DataFrame]) -> pd.DataFrame:
    """Create regional age/sex/ethnicity controls by population type."""

    # Load input data into separate variables for cleaner manipulation
    region_ase_total = controls_inputs["region_ase_total"]
    region_gq_ase_dist = controls_inputs["region_gq_ase_dist"]
    region_pop_type = controls_inputs["region_pop_type"]

    # Scale the regional age/sex/ethnicity total controls to the regional population
    region_ase_total["population"] = utils.integerize_1d(
        data=region_ase_total["population"].astype(float),
        control=region_pop_type["value"].sum(),
    )

    # Calculate the group quarters age/sex/ethnicity population
    # Pivot the group quarters age/sex/ethnicity population by type
    # Such that age/sex/ethnicity categories are rows
    # And group quarters population by type are columns
    gq_pop = (
        region_gq_ase_dist.merge(
            right=region_pop_type, left_on="gq_type", right_on="pop_type"
        )
        .assign(value=lambda x: x["value"] * x["distribution"])
        .sort_values(by=["pop_type"])
        .pivot(
            index=["age_group", "sex", "ethnicity"],
            columns="pop_type",
            values="value",
        )
        .sort_index()
    )

    # Create row marginal controls for age/sex/ethnicity categories
    row_ctrls = region_ase_total.sort_values(by=["age_group", "sex", "ethnicity"])[
        "population"
    ].to_numpy()

    # Create column marginal controls for group quarters population by type
    col_ctrls = (
        region_pop_type[region_pop_type["pop_type"] != "Household Population"]
        .sort_values(by=["pop_type"])["value"]
        .to_numpy()
    )

    # Integerize the group quarters age/sex/ethnicity population by type
    integerized_values = utils.integerize_2d(
        data=gq_pop.to_numpy(),
        row_ctrls=row_ctrls,
        col_ctrls=col_ctrls,
        condition="less than",
    )

    # Assign results back to DataFrame
    gq_pop[list(gq_pop.columns)] = integerized_values

    # Calculate the household age/sex/ethnicity population as the remainder
    # Return the regional age/sex/ethnicity controls by population type
    return (
        region_ase_total.merge(
            right=gq_pop.assign(gq=lambda x: x.sum(axis=1)).reset_index(),
            on=["age_group", "sex", "ethnicity"],
        )
        .assign(hhp=lambda x: x["population"] - x["gq"])
        .drop(columns=["population", "gq"])
        .rename(columns={"hhp": "Household Population"})
        .melt(
            id_vars=["run_id", "year", "age_group", "sex", "ethnicity"],
            var_name="pop_type",
        )
    )


def _validate_controls_outputs(controls_outputs: pd.DataFrame) -> None:
    """Validate the calculated regional age/sex/ethnicity controls"""
    tests.validate_data(
        "Regional ASE Controls",
        controls_outputs,
        row_count={"key_columns": {"pop_type", "age_group", "sex", "ethnicity"}},
        negative={},
        null={},
    )


def _insert_controls(controls_outputs: pd.DataFrame) -> None:
    """Insert regional age/sex/ethnicity controls to database."""
    with utils.ESTIMATES_ENGINE.connect() as conn:
        controls_outputs.to_sql(
            name="controls_ase",
            con=conn,
            schema="inputs",
            if_exists="append",
            index=False,
        )


def _get_seed_inputs(year: int) -> dict[str, pd.DataFrame]:
    """Get inputs required to generate census tract age/sex/ethnicity seed data."""
    with utils.ESTIMATES_ENGINE.connect() as conn:
        # Get the Age/Sex B010001 table data
        with open(utils.SQL_FOLDER / "ase/get_B01001.sql") as file:
            b01001 = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "year": year,
                },
            )

        # Get the Ethnicity B03002 table data
        with open(utils.SQL_FOLDER / "ase/get_B03002.sql") as file:
            b03002 = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "year": year,
                },
            )

        # Get Age/Sex/Ethnicity data from B01001(B-I) table data
        with open(utils.SQL_FOLDER / "ase/get_B01001(B-I).sql") as file:
            b01001_b_i = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "year": year,
                },
            )

    return {"b01001": b01001, "b03002": b03002, "b01001_b_i": b01001_b_i}


def _create_seed(seed_inputs: dict[str, pd.DataFrame]) -> pd.DataFrame:
    """Create census tract age/sex/ethnicity seed data."""
    # Create dictionary of DataFrames and their dimensions to be used in IPF
    dimensions = {
        "b01001": {"labels": ["age_group", "sex"], "values": [0, 1]},
        "b03002": {"labels": ["ethnicity"], "values": [2]},
        "b01001_b_i": {
            "labels": ["age_group", "sex", "ethnicity"],
            "values": [0, 1, 2],
        },
    }

    output = []
    # Within each census tract
    for tract in seed_inputs["b01001_b_i"]["tract"].unique():
        # Create inputs to IPF of numpy ndarrays
        ipf_inputs = {}
        for table, metadata in dimensions.items():
            frame = (
                seed_inputs[table][seed_inputs[table]["tract"] == tract]
                .groupby(metadata["labels"])["value"]
                .sum()
            )

            if len(metadata["labels"]) == 1:
                ipf_inputs[table] = frame.to_numpy()
            else:
                ipf_inputs[table] = np.reshape(
                    frame.to_numpy(), tuple(map(len, frame.index.levels))
                )

        # Run IPF
        ipf = ipfn.ipfn.ipfn(
            ipf_inputs["b01001_b_i"],
            aggregates=[ipf_inputs["b01001"], ipf_inputs["b03002"]],
            dimensions=[
                dimensions["b01001"]["values"],
                dimensions["b03002"]["values"],
            ],
            max_iteration=10000,
        )

        # Transform result back to DataFrame
        result = (
            seed_inputs["b01001_b_i"][dimensions["b01001_b_i"]["labels"]]
            .drop_duplicates()
            .sort_values(by=dimensions["b01001_b_i"]["labels"])  # type: ignore
            .assign(tract=tract, value=ipf.iteration().flatten())  # type: ignore
        )

        # Append to output list
        output.append(result)

    return pd.concat(output, ignore_index=True)


def _get_ase_inputs(year: int) -> dict[str, pd.DataFrame]:
    with utils.ESTIMATES_ENGINE.connect() as conn:
        # Get the MGRA-level population by type data
        with open(utils.SQL_FOLDER / "ase/get_mgra_pop_type.sql") as file:
            mgra_pop_type = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

        # Get special MGRAs for age/sex restrictions
        with open(utils.SQL_FOLDER / "ase/get_special_mgras.sql") as file:
            special_mgras = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "year": year,
                    "mgra_version": utils.MGRA_VERSION,
                },
            )

    controls_ase = _create_controls(_get_controls_inputs(year=year))
    seed_tracts = _create_seed(_get_seed_inputs(year=year))

    return {
        "year": year,
        "mgra_pop_type": mgra_pop_type,
        "special_mgras": special_mgras,
        "controls_ase": controls_ase,
        "seed_tracts": seed_tracts,
    }


def _validate_ase_inputs(year: int, ase_inputs: dict[str, pd.DataFrame]) -> None:
    """Validate the age/sex/ethnicity input data"""
    # Note that the year and controls_ase are not validated here
    # As one is simply a parameter and the other is validated prior to this
    tests.validate_data(
        "MGRA Population by Type Estimates",
        ase_inputs["mgra_pop_type"],
        row_count={"key_columns": {"mgra", "pop_type"}},
        negative={},
        null={},
    )
    tests.validate_data(
        "ACS Census Tract Seed Data",
        ase_inputs["seed_tracts"],
        row_count={
            "key_columns": {"tract", "age_group", "sex", "ethnicity"},
            "year": year,
        },
        negative={},
        null={},
    )
    tests.validate_data("Special MGRAs", ase_inputs["special_mgras"], negative={})


def _create_ase(ase_inputs: dict[str, pd.DataFrame]) -> dict[str, pd.DataFrame]:
    """Create MGRA age/sex/ethnicity population by type."""
    # Merge the MGRA-level population by type data with the seed data
    # And provide special MGRA information to apply age/sex restrictions
    seed_mgras = (
        ase_inputs["mgra_pop_type"]
        .merge(right=ase_inputs["seed_tracts"], on="tract", suffixes=("_delete", ""))
        .merge(
            right=ase_inputs["special_mgras"],
            on=["mgra", "pop_type"],
            how="left",
            suffixes=("", "_special"),
        )
        .merge(
            right=pd.DataFrame.from_dict(utils.AGE_MAPPING, orient="index").reset_index(
                names="age_group"
            ),
            on="age_group",
        )
    )

    # Apply age/sex restrictions
    # Set 0-valued seed data to 1 where special MGRA data exists
    # To allow greater IPF flexibility within restricted categories
    seed_mgras.loc[
        (seed_mgras["value"] == 0)
        & (
            (seed_mgras["sex_special"].notna())
            | (seed_mgras["min_age"].notna())
            | (seed_mgras["max_age"].notna())
        ),
        "value",
    ] = 1

    # Set the MGRA-level seed data to 0 for special MGRAs
    # Where the age/sex restrictions are violated
    # Seed data set to 0 remains 0 in an IPF process
    seed_mgras.loc[
        (seed_mgras["sex"] != seed_mgras["sex_special"])
        & (seed_mgras["sex_special"].notna()),
        "value",
    ] = 0

    seed_mgras.loc[
        (seed_mgras["max"] < seed_mgras["min_age"])
        | (seed_mgras["min"] > seed_mgras["max_age"]),
        "value",
    ] = 0

    # Add the MGRA seed data to the input dictionary of DataFrames
    ase_inputs["seed_mgras"] = seed_mgras

    # Create dictionary of DataFrames and their dimensions to be used in IPF
    dimensions = {
        "controls_ase": {
            "labels": ["pop_type", "age_group", "sex", "ethnicity"],
            "values": [1, 2, 3, 4],
        },
        "mgra_pop_type": {
            "labels": ["mgra", "pop_type"],
            "values": [0, 1],
        },
        "seed_mgras": {
            "labels": ["mgra", "pop_type", "age_group", "sex", "ethnicity"],
            "values": [0, 1, 2, 3, 4],
        },
    }

    # Create inputs to IPF of numpy ndarrays
    ipf_inputs = {}
    for table, metadata in dimensions.items():
        frame = ase_inputs[table].groupby(metadata["labels"])["value"].sum()

        if len(metadata["labels"]) == 1:
            ipf_inputs[table] = frame.to_numpy()
        else:
            ipf_inputs[table] = np.reshape(
                frame.to_numpy(), tuple(map(len, frame.index.levels))
            )

    # Run IPF
    ipf = ipfn.ipfn.ipfn(
        ipf_inputs["seed_mgras"],
        aggregates=[ipf_inputs["controls_ase"], ipf_inputs["mgra_pop_type"]],
        dimensions=[
            dimensions["controls_ase"]["values"],
            dimensions["mgra_pop_type"]["values"],
        ],
        max_iteration=10000,
    )

    # Transform result back to DataFrame
    ipf_result = (
        ase_inputs["seed_mgras"][dimensions["seed_mgras"]["labels"]]
        .drop_duplicates()
        .sort_values(by=dimensions["seed_mgras"]["labels"])  # type: ignore
        .assign(value=ipf.iteration().flatten())  # type: ignore
    )

    # Integerize the IPF results
    result = {}
    # For each population type
    for pop_type in ipf_result["pop_type"].unique():
        # Pivot data into numpy array
        # Set age/sex/ethnicity to columns
        # And MGRA population to rows
        population = (
            ipf_result.query("pop_type == @pop_type")
            .sort_values(by=["age_group", "sex", "ethnicity"])
            .pivot(
                index=["mgra"],
                columns=["age_group", "sex", "ethnicity"],
                values="value",
            )
            .sort_index()
        )

        # Create row marginal controls for MGRA population
        row_ctrls = (
            ase_inputs["mgra_pop_type"]
            .query("pop_type == @pop_type")
            .sort_values(by=["mgra"])["value"]
            .to_numpy()
        )

        # Create column marginal controls for age/sex/ethnicity
        col_ctrls = (
            ase_inputs["controls_ase"]
            .query("pop_type == @pop_type")
            .sort_values(by=["age_group", "sex", "ethnicity"])["value"]
            .to_numpy()
        )

        # Integerize the age/sex/ethnicity population
        integerized_values = utils.integerize_2d(
            data=population.to_numpy(),
            row_ctrls=row_ctrls,
            col_ctrls=col_ctrls,
            condition="exact",
        )

        # Assign results back to DataFrame
        population[list(population.columns)] = integerized_values

        # Append to output dictionary in long-format with correct labels
        population = population.melt(ignore_index=False).reset_index()
        population["value"] = population["value"].astype(int)
        population["pop_type"] = pop_type
        population["run_id"] = utils.RUN_ID
        population["year"] = ase_inputs["year"]
        result[pop_type] = population

    # Return integerized results
    return result


def _validate_ase_outputs(ase_outputs: dict[str, pd.DataFrame]) -> None:
    """Validate the age/sex/ethnicity output data"""
    for pop_type, output in ase_outputs.items():
        tests.validate_data(
            "MGRA Age/Sex/Ethnicity Population: " + pop_type,
            output,
            row_count={"key_columns": {"mgra", "age_group", "sex", "ethnicity"}},
            negative={},
            null={},
        )


def _insert_ase(ase_outputs: dict[str, pd.DataFrame]) -> None:
    """Insert age/sex/ethnicity population by type to database."""
    for pop_type, output in ase_outputs.items():
        # Convert the DataFrame to a Polars DataFrame
        # Polars used solely for write to CSV performance
        pl_df = pl.from_pandas(
            output[
                [
                    "run_id",
                    "year",
                    "mgra",
                    "pop_type",
                    "age_group",
                    "sex",
                    "ethnicity",
                    "value",
                ]
            ],
            include_index=False,
        )

        # Write the DataFrame to a CSV file
        pl_df.write_csv(
            utils.BULK_INSERT_STAGING / (pop_type + ".txt"),
            include_header=False,
            separator="|",
            quote_style="never",
        )

        # Bulk insert the CSV file into the production database
        with utils.ESTIMATES_ENGINE.connect() as conn:
            fp = (utils.BULK_INSERT_STAGING / (pop_type + ".txt")).as_posix()
            query = sql.text(
                f"""
                    BULK INSERT [outputs].[ase]
                    FROM '{fp}'
                    WITH (
                        TABLOCK,
                        MAXERRORS=0,
                        FIELDTERMINATOR = '|',
                        ROWTERMINATOR = '0x0A'
                    )
                """
            )
            conn.execute(query)
            conn.commit()

        # Remove the temporary CSV file
        (utils.BULK_INSERT_STAGING / (pop_type + ".txt")).unlink()
