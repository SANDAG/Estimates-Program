# Container for the Population by Age Sex Ethnicity module. See the Estimates-Program
# wiki page for more details:
# https://github.com/SANDAG/Estimates-Program/wiki/Population-by-Age-Sex-Ethnicity

import functools
import logging

import numpy as np
import pandas as pd
import polars as pl
import sqlalchemy as sql

import python.tests as tests
import python.utils as utils

generator = np.random.default_rng(utils.RANDOM_SEED)
logger = logging.getLogger(__name__)


def run_ase(year: int) -> None:
    """Orchestrator function for age/sex/ethnicity population by type.

    Creates regional age/sex/ethnicity controls by population type. Then
    calculates MGRA level age/sex/ethnicity population by type using these
    regional controls, synthesized census tract level seed data, and MGRA
    level population by type generated by the Population by Type module.
    Results are inserted into the production database along with the regional
    controls.

    Functionality is segmented into functions for code encapsulation:
        _get_controls_inputs - Get regional age/sex/ethnicity controls from
            CA DOF for total population, regional age/sex/ethnicity group
            quarters by type distributions from the 5-year ACS PUMS, and
            regional population by type generated by the Population by Type
            module
        _validate_controls_inputs - Validate the controls input data from the
            above function
        _create_controls - Calculate regional age/sex/ethnicity controls by
            population type
        _validate_controls_outputs - Validate the controls output data from
            the above function
        _insert_controls - Insert regional age/sex/ethnicity controls by
            population type to production database
        _get_seed_inputs - Get 5-year ACS Detailed Tables B010001, B03002, and
            B01001(B-I)
        _create_seed - Calculate census tract level age/sex/ethnicity seed
            data for total population
        _get_ase_inputs - Get MGRA population by type generated by the
            Population by Type module, special MGRAs with age/sex restrictions
            by population type, regional age/sex/ethnicity controls by
            population type, and census tract level age/sex/ethnicity seed
            data for total population
        _validate_ase_inputs - Validate the age/sex/ethnicity input data from
            the above function
        _create_ase - Calculate MGRA level age/sex/ethnicity population by
            population type
        _validate_ase_outputs - Validate the age/sex/ethnicity output data from
            the above function
        _insert_ase - Insert MGRA level age/sex/ethnicity population by
            population type to production database

    Args:
        year (int): estimates year
    """
    # Calculate regional age/sex/ethnicity controls by population type
    controls_inputs = _get_controls_inputs(year)
    _validate_controls_inputs(controls_inputs)

    controls_outputs = _create_controls(controls_inputs)
    _validate_controls_outputs(controls_outputs)

    _insert_controls(controls_outputs)

    # Calculate MGRA age/sex/ethnicity population by population type
    ase_inputs = _get_ase_inputs(year)
    _validate_ase_inputs(year, ase_inputs)

    ase_outputs = _create_ase(year, ase_inputs)
    _validate_ase_outputs(ase_outputs)

    _insert_ase(ase_outputs)


@functools.lru_cache(maxsize=1)
def _get_controls_inputs(year: int) -> dict[str, pd.DataFrame]:
    """Get inputs required to calculate regional age/sex/ethnicity controls."""
    with utils.ESTIMATES_ENGINE.connect() as con:
        # Get regional age/sex/ethnicity controls for total population
        with open(utils.SQL_FOLDER / "ase/get_region_ase_total.sql") as file:
            region_ase_total = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

        # Get regional age/sex/ethnicity group quarters distributions
        with open(utils.SQL_FOLDER / "ase/get_region_gq_ase_dist.sql") as file:
            region_gq_ase_dist = utils.read_sql_query_fallback(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

        # Get regional population by type output generated by Estimates program
        with open(utils.SQL_FOLDER / "ase/get_region_pop_type.sql") as file:
            region_pop_type = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

    return {
        "region_ase_total": region_ase_total,
        "region_gq_ase_dist": region_gq_ase_dist,
        "region_pop_type": region_pop_type,
    }


def _validate_controls_inputs(controls_inputs: dict[str, pd.DataFrame]) -> None:
    """Validate the regional age/sex/ethnicity controls input data"""
    tests.validate_data(
        "CA DOF Regional ASE Total Controls",
        controls_inputs["region_ase_total"],
        row_count={"key_columns": {"age_group", "sex", "ethnicity"}},
        negative={},
        null={},
    )
    tests.validate_data(
        "ACS Regional GQ ASE Distribution",
        controls_inputs["region_gq_ase_dist"],
        row_count={"key_columns": {"gq_type", "age_group", "sex", "ethnicity"}},
        negative={},
        null={},
    )
    tests.validate_data(
        "Regional Population by Type Estimates",
        controls_inputs["region_pop_type"],
        row_count={"key_columns": {"pop_type"}},
        negative={},
        null={},
    )


def _create_controls(controls_inputs: dict[str, pd.DataFrame]) -> pd.DataFrame:
    """Create regional age/sex/ethnicity controls by population type."""

    # This function is called multiple times, so in order to have consistent output it
    # needs to use it's very own random number generator
    local_generator = np.random.default_rng(seed=utils.RANDOM_SEED)

    # Load input data into separate variables for cleaner manipulation
    region_ase_total = controls_inputs["region_ase_total"]
    region_gq_ase_dist = controls_inputs["region_gq_ase_dist"]
    region_pop_type = controls_inputs["region_pop_type"]

    # Scale the regional age/sex/ethnicity total controls to the regional population
    region_ase_total = region_ase_total.sort_values(
        by=["age_group", "sex", "ethnicity"]
    ).reset_index(drop=True)
    region_ase_total["population"] = utils.integerize_1d(
        data=region_ase_total["population"].astype(float),
        control=region_pop_type["value"].sum(),
        generator=local_generator,
    )

    # Calculate the group quarters age/sex/ethnicity population
    # Pivot the group quarters age/sex/ethnicity population by type
    # Such that age/sex/ethnicity categories are rows
    # And group quarters population by type are columns
    gq_pop = (
        region_gq_ase_dist.merge(
            right=region_pop_type, left_on="gq_type", right_on="pop_type"
        )
        .assign(value=lambda x: x["value"] * x["distribution"])
        .sort_values(by=["pop_type"])
        .pivot(
            index=["age_group", "sex", "ethnicity"],
            columns="pop_type",
            values="value",
        )
        .sort_index()
    )

    # Create row marginal controls for age/sex/ethnicity categories
    row_ctrls = (
        region_ase_total.sort_values(by=["age_group", "sex", "ethnicity"])
        .reset_index(drop=True)["population"]
        .to_numpy()
    )

    # Create column marginal controls for group quarters population by type
    col_ctrls = (
        region_pop_type[region_pop_type["pop_type"] != "Household Population"]
        .sort_values(by=["pop_type"])
        .reset_index(drop=True)["value"]
        .to_numpy()
    )

    # Integerize the group quarters age/sex/ethnicity population by type
    integerized_values = utils.integerize_2d(
        data=gq_pop.to_numpy(),
        row_ctrls=row_ctrls,
        col_ctrls=col_ctrls,
        condition="less than",
        generator=local_generator,
    )

    # Assign results back to DataFrame
    gq_pop[list(gq_pop.columns)] = integerized_values

    # Calculate the household age/sex/ethnicity population as the remainder
    # Return the regional age/sex/ethnicity controls by population type
    return (
        region_ase_total.merge(
            right=gq_pop.assign(gq=lambda x: x.sum(axis=1)).reset_index(),
            on=["age_group", "sex", "ethnicity"],
        )
        .assign(hhp=lambda x: x["population"] - x["gq"])
        .drop(columns=["population", "gq"])
        .rename(columns={"hhp": "Household Population"})
        .melt(
            id_vars=["run_id", "year", "age_group", "sex", "ethnicity"],
            var_name="pop_type",
        )
    )


def _validate_controls_outputs(controls_outputs: pd.DataFrame) -> None:
    """Validate the calculated regional age/sex/ethnicity controls"""
    tests.validate_data(
        "Regional ASE Controls",
        controls_outputs,
        row_count={"key_columns": {"pop_type", "age_group", "sex", "ethnicity"}},
        negative={},
        null={},
    )


def _insert_controls(controls_outputs: pd.DataFrame) -> None:
    """Insert regional age/sex/ethnicity controls to database."""
    with utils.ESTIMATES_ENGINE.connect() as con:
        controls_outputs.to_sql(
            name="controls_ase",
            con=con,
            schema="inputs",
            if_exists="append",
            index=False,
        )


def _get_seed_inputs(year: int) -> dict[str, pd.DataFrame]:
    """Get inputs required to generate census tract age/sex/ethnicity seed data."""
    with utils.ESTIMATES_ENGINE.connect() as con:
        # Get the Age/Sex B010001 table data
        with open(utils.SQL_FOLDER / "ase/get_B01001.sql") as file:
            b01001 = utils.read_sql_query_fallback(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "year": year,
                },
            )

        # Get the Ethnicity B03002 table data
        with open(utils.SQL_FOLDER / "ase/get_B03002.sql") as file:
            b03002 = utils.read_sql_query_fallback(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "year": year,
                },
            )

        # Get Age/Sex/Ethnicity data from B01001(B-I) table data
        with open(utils.SQL_FOLDER / "ase/get_B01001(B-I).sql") as file:
            b01001_b_i = utils.read_sql_query_fallback(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "year": year,
                },
            )

    return {"b01001": b01001, "b03002": b03002, "b01001_b_i": b01001_b_i}


def _create_seed(seed_inputs: dict[str, pd.DataFrame]) -> pd.DataFrame:
    """Create census tract age/sex/ethnicity seed data."""

    # Unfortunately, our B01001B-I table is intentionally missing B01001F, which means
    # some pre-processing is necessary to account for the missing data. In particular,
    # it means that within a tract, B01001 and B03002 controls may not agree on the
    # total population. Additionally, B01001B-I may have all zero data along a dimension
    # with a non-zero control. Both these issues will be resolved here

    # Processing is easiest on a tract by tract basis, so we'll store the result from
    # each tract separately then combine at the end
    output = []
    for tract in np.sort(seed_inputs["b01001_b_i"]["tract"].unique()):

        # Collect the data for IPF. This means the raw seed data, row controls, and
        # column controls.
        seed = (
            seed_inputs["b01001_b_i"]
            .loc[lambda df: df["tract"] == tract]
            .sort_values(by=utils.ASE)
            .drop(columns=["tract"])
            .pivot_table(
                values="value", index="ethnicity", columns=["age_group", "sex"]
            )
        )

        # Somewhat arbitrarily, we set B03002 (ethnicity data) as row controls and
        # B01001 (age/sex data) as column controls
        row_controls = (
            seed_inputs["b03002"]
            .loc[lambda df: df["tract"] == tract]
            .sort_values(by="ethnicity")["value"]
            .to_numpy()
        )
        col_controls = (
            seed_inputs["b01001"]
            .loc[lambda df: df["tract"] == tract]
            .sort_values(by=["age_group", "sex"])["value"]
            .to_numpy()
        )

        # Finally, there's one more thing to fix. The ACS category of "Some other
        # race alone`" is excluded from Estimates, and has been removed from B01001B-I
        # (via the exclusion of B01001F) and removed from the B03002 marginal control.
        # But it can`'t be removed from B01001, which means that:
        # 1: Marginal controls may sum to different values, in which case we set the
        #    rows to the column value and...
        if row_controls.sum() != col_controls.sum():
            row_controls = utils.integerize_1d(
                row_controls,
                col_controls.sum(),
                methodology="weighted_random",
                generator=generator,
            )

        # 2: A B01001 marginal control may be non-zero, but be associated with all zero
        #    data, in which case we assume that the missing "Some other race alone" is
        #    evenly distributed between all other race/eth categories. To prevent this
        #    distribution from effecting other race/eth categories, it's set to the
        #    tiny value of .001
        if np.any((col_controls > 0) & (seed.sum(axis=0) == 0)):
            col_idx_to_adjust = np.where(
                (col_controls > 0) & (seed.sum(axis=0).to_numpy() == 0)
            )
            for col_idx in col_idx_to_adjust:
                seed[seed.columns[col_idx]] = 0.001

        # Plug the data into IPF
        post_ipf_data = utils.ipf(
            seed.to_numpy(),
            [row_controls, col_controls],
        )

        # Restore the metadata and original table structure
        seed[:] = post_ipf_data
        seed = seed.melt(ignore_index=False).reset_index(drop=False).assign(tract=tract)

        # Append to output list
        output.append(seed)

    return pd.concat(output, ignore_index=True)


def _get_ase_inputs(year: int) -> dict[str, pd.DataFrame]:
    with utils.ESTIMATES_ENGINE.connect() as con:
        # Get Households by MGRA
        with open(utils.SQL_FOLDER / "ase" / "get_mgra_hh.sql") as file:
            hh = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

        # Get the MGRA-level population by type data
        with open(utils.SQL_FOLDER / "ase" / "get_mgra_pop_type.sql") as file:
            mgra_pop_type = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                },
            )

        # Get special MGRAs for age/sex restrictions
        with open(utils.SQL_FOLDER / "ase" / "get_special_mgras.sql") as file:
            special_mgras = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "year": year,
                    "mgra_version": utils.MGRA_VERSION,
                },
            )

    controls_ase = _create_controls(_get_controls_inputs(year=year))
    seed_tracts = _create_seed(_get_seed_inputs(year=year))

    return {
        "year": year,
        "hh": hh,
        "mgra_pop_type": mgra_pop_type,
        "special_mgras": special_mgras,
        "controls_ase": controls_ase,
        "seed_tracts": seed_tracts,
    }


def _validate_ase_inputs(year: int, ase_inputs: dict[str, pd.DataFrame]) -> None:
    """Validate the age/sex/ethnicity input data"""
    tests.validate_data(
        "MGRA Households Estimates",
        ase_inputs["hh"],
        row_count={"key_columns": {"mgra"}},
        negative={},
        null={},
    )
    tests.validate_data(
        "MGRA Population by Type Estimates",
        ase_inputs["mgra_pop_type"],
        row_count={"key_columns": {"mgra", "pop_type"}},
        negative={},
        null={},
    )
    tests.validate_data(
        "ACS Census Tract Seed Data",
        ase_inputs["seed_tracts"],
        row_count={
            "key_columns": {"tract", "age_group", "sex", "ethnicity"},
            "year": year,
        },
        negative={},
        null={},
    )
    tests.validate_data("Special MGRAs", ase_inputs["special_mgras"], negative={})
    tests.validate_data(
        "Regional ASE Controls",
        ase_inputs["controls_ase"],
        row_count={"key_columns": {"pop_type", "age_group", "sex", "ethnicity"}},
        negative={},
        null={},
    )


def _create_ase(
    year: int, ase_inputs: dict[str, pd.DataFrame]
) -> dict[str, pd.DataFrame]:
    """Create MGRA age/sex/ethnicity population by type."""
    # Merge the MGRA-level population by type data with the seed data
    # And provide special MGRA information to apply age/sex restrictions
    seed_mgras = (
        ase_inputs["mgra_pop_type"]
        .merge(right=ase_inputs["seed_tracts"], on="tract", suffixes=("_delete", ""))
        .merge(
            right=ase_inputs["special_mgras"],
            on=["mgra", "pop_type"],
            how="left",
            suffixes=("", "_special"),
        )
        .merge(
            right=pd.DataFrame.from_dict(utils.AGE_MAPPING, orient="index").reset_index(
                names="age_group"
            ),
            on="age_group",
        )
    )

    # Apply age/sex restrictions
    # Set 0-valued seed data to 1 where special MGRA data exists to allow greater IPF
    # flexibility within restricted categories
    seed_mgras.loc[
        (seed_mgras["value"] == 0)
        & (
            (seed_mgras["sex_special"].notna())
            | (seed_mgras["min_age"].notna())
            | (seed_mgras["max_age"].notna())
        ),
        "value",
    ] = 1

    # Set the MGRA-level seed data to 0 for special MGRAs where the age/sex restrictions
    # are violated. Seed data set to 0 remains 0 in an IPF process
    seed_mgras.loc[
        (seed_mgras["sex"] != seed_mgras["sex_special"])
        & (seed_mgras["sex_special"].notna()),
        "value",
    ] = 0
    seed_mgras.loc[
        (seed_mgras["max"] < seed_mgras["min_age"])
        | (seed_mgras["min"] > seed_mgras["max_age"]),
        "value",
    ] = 0

    # The way the IPF function works means it's easiest to process the data for every
    # pop type, then combine back together
    post_ipf_data = []
    for pop_type in seed_mgras["pop_type"].unique():

        # Filter the data to this population type and transform into a 2D array
        pop_type_seed = (
            seed_mgras[seed_mgras["pop_type"] == pop_type]
            # Take only a subset of the original data for speed
            [["mgra", "age_group", "sex", "ethnicity", "value"]]
            # Sort values to ensure a consistent ordering
            .sort_values(by=["mgra", "age_group", "sex", "ethnicity"])
            # Re-shape to 2D
            .pivot(index="mgra", columns=["age_group", "sex", "ethnicity"])
        )

        # Get the row controls (aka MGRA population by type)
        row_controls = (
            ase_inputs["mgra_pop_type"]
            .loc[lambda df: df["pop_type"] == pop_type][["mgra", "value"]]
            .sort_values(by="mgra")
        )

        # Get the column controls (aka regional population by type and by ASE)
        col_controls = (
            ase_inputs["controls_ase"]
            .loc[lambda df: df["pop_type"] == pop_type][
                ["age_group", "sex", "ethnicity", "value"]
            ]
            .sort_values(by=["age_group", "sex", "ethnicity"])
        )

        # Run IPF
        pop_type_post_ipf_data = utils.ipf(
            data=pop_type_seed.to_numpy(),
            marginals=[
                row_controls["value"].to_numpy(),
                col_controls["value"].to_numpy(),
            ],
        )

        # Restore the original index/columns
        pop_type_seed.loc[:] = pop_type_post_ipf_data

        # Reshape, add back some metadata columns and store. No joke, "value" is not a
        # valid name of the "value_name" column, so it's named "temp" and immediately
        # changed to "value"
        post_ipf_data.append(
            pop_type_seed.reset_index(drop=False)
            .melt(id_vars=[("mgra", "", "", "")], value_name="temp", ignore_index=False)
            .drop(columns=[None])
            .rename(columns={("mgra", "", "", ""): "mgra", "temp": "value"})
            .sort_values(by=["mgra", "age_group", "sex", "ethnicity"])
            .assign(pop_type=pop_type)
        )

    # Combine the IPF results from separate pop types back into one table
    ipf_result = pd.concat(post_ipf_data)

    # Integerize the IPF results
    result = {}
    # For each population type
    for pop_type in np.sort(ipf_result["pop_type"].unique()):
        logger.info("Integerizing population for " + pop_type)

        # Pivot data into numpy array
        # Set age/sex/ethnicity to columns
        # And MGRA population to rows
        population = (
            ipf_result.query("pop_type == @pop_type")
            .sort_values(by=["age_group", "sex", "ethnicity"])
            .pivot(
                index=["mgra"],
                columns=["age_group", "sex", "ethnicity"],
                values="value",
            )
            .sort_index()
        )

        # Create row marginal controls for MGRA population
        row_ctrls = (
            ase_inputs["mgra_pop_type"]
            .query("pop_type == @pop_type")
            .sort_values(by=["mgra"])["value"]
            .reset_index(drop=True)
            .to_numpy()
        )

        # Create column marginal controls for age/sex/ethnicity
        col_ctrls = (
            ase_inputs["controls_ase"]
            .query("pop_type == @pop_type")
            .sort_values(by=["age_group", "sex", "ethnicity"])
            .reset_index(drop=True)["value"]
            .to_numpy()
        )

        # Integerize the age/sex/ethnicity population
        integerized_values = utils.integerize_2d(
            data=population.to_numpy(),
            row_ctrls=row_ctrls,
            col_ctrls=col_ctrls,
            condition="exact",
            nearest_neighbors=list(range(5, 55, 5)),
            generator=generator,
        )

        # Assign results back to DataFrame
        population[list(population.columns)] = integerized_values

        # Append to output dictionary in long-format with correct labels
        population = population.melt(ignore_index=False).reset_index()
        population["value"] = population["value"].astype(int)
        population["pop_type"] = pop_type
        population["run_id"] = utils.RUN_ID
        population["year"] = year
        result[pop_type] = population

    # This section defines special balancing processes specific to population types
    for pop_type in result:
        # The following section ensures that MGRAs with hard restrictions defined by the
        # special MGRAs table are not violated by the integerization process. Note that
        # only Group Quarters - Institutional Correctional Facilities have special MGRAs
        if pop_type == "Group Quarters - Institutional Correctional Facilities":
            logger.info("Balancing Special MGRAs")

            # Get the special MGRAs and their restrictions
            special_mgras = ase_inputs["special_mgras"].query("pop_type == @pop_type")

            # Get special MGRAs in a/s/e result
            # Note that all MGRAs in this population type with persons are special
            special_ase = (
                result[pop_type]
                .merge(
                    right=special_mgras,
                    on="mgra",
                    how="inner",
                    suffixes=("", "_special"),
                )
                .merge(
                    right=pd.DataFrame.from_dict(
                        utils.AGE_MAPPING, orient="index"
                    ).reset_index(names="age_group"),
                    on="age_group",
                )
                .assign(
                    ase_concat=lambda x: x["age_group"]
                    + "|"
                    + x["sex"]
                    + "|"
                    + x["ethnicity"]
                )
            )

            # Indicate a/s/e categories that are restricted
            special_ase["restricted"] = (
                (
                    (special_ase["sex"] != special_ase["sex_special"])
                    & (special_ase["sex_special"].notna())
                )
                | (special_ase["max"] < special_ase["min_age"])
                | (special_ase["min"] > special_ase["max_age"])
            )

            # For each MGRA in the special MGRAs
            for mgra in np.sort(special_mgras["mgra"].unique()):
                # Store values of un-restricted categories for the MGRA
                unrestricted_ase = special_ase.query(
                    "mgra == @mgra and not restricted"
                )["ase_concat"]

                # Get non-zero restricted categories
                violations = special_ase.query(
                    "mgra == @mgra and restricted and value > 0"
                )

                # For each non-zero restricted category
                for violation_idx in violations.index.to_list():
                    # Get the age/sex/ethnicity category of the violation
                    violation_ase = special_ase.loc[violation_idx]["ase_concat"]

                    # Until the category has been zero-ed out
                    while special_ase.loc[violation_idx, "value"] > 0:
                        # Get eligible donor MGRAs
                        donors = list(
                            # These are MGRAs without restrictions on the category
                            set(
                                special_ase.query(
                                    "not restricted and ase_concat == @violation_ase"
                                )["mgra"].to_list()
                            )
                            &
                            # That also have a non-zero value in a category that is not restricted
                            set(
                                special_ase.query(
                                    "not restricted and value > 0 and ase_concat in @unrestricted_ase"
                                )["mgra"].to_list()
                            )
                        )

                        # If no eligible donor MGRAs found, skip and try next category
                        if not donors:
                            logger.warning(f"Unbalanced Special MGRA: {mgra}")
                            logger.warning(f"Restricted Category: {violation_ase}")
                            break  # skip balancing
                        # If donor MGRAs found continue balancing
                        else:
                            # Subtract one from restricted category
                            special_ase.loc[violation_idx, "value"] -= 1

                            # Find the donor with the largest value in the restricted category
                            # Add one to the donor MGRA for the restricted category
                            donor_idx = special_ase.query(
                                "mgra in @donors and ase_concat == @violation_ase"
                            )["value"].idxmax()
                            special_ase.loc[donor_idx, "value"] += 1
                            donor_mgra = special_ase.loc[donor_idx, "mgra"]

                            # Find largest un-restricted category within the donor
                            # And subtract one from the un-restricted category
                            balance_idx = special_ase.query(
                                "mgra == @donor_mgra and not restricted and value > 0 and ase_concat in @unrestricted_ase"
                            )["value"].idxmax()
                            special_ase.loc[balance_idx, "value"] -= 1
                            balance_ase = special_ase.loc[balance_idx]["ase_concat"]

                            # Add one to the special MGRA for the un-restricted category
                            special_ase.loc[
                                (special_ase["mgra"] == mgra)
                                & (special_ase["ase_concat"] == balance_ase),
                                "value",
                            ] += 1

            # Merge the adjusted data back into the result set
            result[pop_type] = result[pop_type].merge(
                right=special_ase[["mgra", "age_group", "sex", "ethnicity", "value"]],
                on=["mgra", "age_group", "sex", "ethnicity"],
                how="left",
                suffixes=("", "_adjusted"),
            )

            result[pop_type]["value"] = (
                np.where(
                    result[pop_type]["value_adjusted"].isna(),
                    result[pop_type]["value"],
                    result[pop_type]["value_adjusted"],
                )
            ).astype(int)

            result[pop_type].drop(columns="value_adjusted", inplace=True)

        # The following section seeks to balance MGRAs such that the number of households
        # is greater than or equal to the number of householders (i.e., household population >= 15)
        elif pop_type == "Household Population":
            logger.info("Balancing Householders")

            # Within the Household Population Type
            # Get MGRAs where Household Population >= 15 is less than Households
            householders = []
            for age_group, age_range in utils.AGE_MAPPING.items():
                if age_range["min"] >= 15:
                    householders.append(age_group)

            problem_mgras = (
                pd.merge(
                    left=result["Household Population"]
                    .query("age_group in @householders")
                    .groupby("mgra")["value"]
                    .sum()
                    .reset_index(),
                    right=ase_inputs["hh"],
                    on="mgra",
                    suffixes=["_head_hh", "_hh"],
                )
                .query("value_head_hh < value_hh")
                .assign(adjustment=lambda x: x["value_hh"] - x["value_head_hh"])
            )

            # For each of these MGRAs
            for row in problem_mgras.itertuples(index=False):
                problem_mgra = row.mgra
                adjustment = row.adjustment

                # While adjustment needed is greater than zero
                while adjustment > 0:
                    # Select largest non-householder age/sex/ethnicity category and subtract one
                    problem_mgra_subtract_idx = (
                        result["Household Population"]
                        .query("mgra == @problem_mgra")
                        .query("age_group not in @householders")["value"]
                        .idxmax()
                    )
                    result["Household Population"].loc[
                        problem_mgra_subtract_idx, "value"
                    ] -= 1

                    # Store the category that was subtracted
                    problem_mgra_subtract_category = {
                        "age_group": result["Household Population"].loc[
                            problem_mgra_subtract_idx, "age_group"
                        ],
                        "sex": result["Household Population"].loc[
                            problem_mgra_subtract_idx, "sex"
                        ],
                        "ethnicity": result["Household Population"].loc[
                            problem_mgra_subtract_idx, "ethnicity"
                        ],
                    }

                    # Find MGRAs where Household Population >= 15 is strictly greater than Households
                    donor_mgras = (
                        pd.merge(
                            left=result["Household Population"]
                            .query("age_group in @householders")
                            .groupby("mgra")["value"]
                            .sum()
                            .reset_index(),
                            right=ase_inputs["hh"],
                            on="mgra",
                            suffixes=["_head_hh", "_hh"],
                        )
                        .query("value_head_hh > value_hh")["mgra"]
                        .to_list()
                    )

                    # Select donor MGRA with the largest age/sex/category that was subtracted and add one
                    donor_mgra_add_idx = (
                        result["Household Population"]
                        .query("mgra in @donor_mgras")
                        .query(
                            f"age_group == '{problem_mgra_subtract_category["age_group"]}'"
                        )
                        .query(f"sex == '{problem_mgra_subtract_category["sex"]}'")
                        .query(
                            f"ethnicity == '{problem_mgra_subtract_category["ethnicity"]}'"
                        )["value"]
                        .idxmax()
                    )
                    result["Household Population"].loc[donor_mgra_add_idx, "value"] += 1
                    donor_mgra = result["Household Population"].loc[
                        donor_mgra_add_idx, "mgra"
                    ]

                    # Select largest householder age/sex/ethnicity category within donor MGRA and subtract one
                    donor_mgra_subtract_idx = (
                        result["Household Population"]
                        .query("mgra == @donor_mgra")
                        .query("age_group in @householders")["value"]
                        .idxmax()
                    )
                    result["Household Population"].loc[
                        donor_mgra_subtract_idx, "value"
                    ] -= 1

                    # Store the category that was subtracted
                    donor_mgra_subtract_category = {
                        "age_group": result["Household Population"].loc[
                            donor_mgra_subtract_idx, "age_group"
                        ],
                        "sex": result["Household Population"].loc[
                            donor_mgra_subtract_idx, "sex"
                        ],
                        "ethnicity": result["Household Population"].loc[
                            donor_mgra_subtract_idx, "ethnicity"
                        ],
                    }

                    # Add one to this category for the MGRA with Household Population >= 15 less than Households
                    problem_mgra_add_idx = (
                        result["Household Population"]
                        .query("mgra == @problem_mgra")
                        .query(
                            f"age_group == '{donor_mgra_subtract_category["age_group"]}'"
                        )
                        .query(f"sex == '{donor_mgra_subtract_category["sex"]}'")
                        .query(
                            f"ethnicity == '{donor_mgra_subtract_category["ethnicity"]}'"
                        )["value"]
                        .index
                    )
                    result["Household Population"].loc[
                        problem_mgra_add_idx, "value"
                    ] += 1

                    # Decrease the adjustment needed by one
                    adjustment -= 1
        else:
            # No additional balancing needed for other population types
            pass

    # Return integerized results
    return result


def _validate_ase_outputs(ase_outputs: dict[str, pd.DataFrame]) -> None:
    """Validate the age/sex/ethnicity output data"""
    for pop_type, output in ase_outputs.items():
        tests.validate_data(
            "MGRA Age/Sex/Ethnicity Population: " + pop_type,
            output,
            row_count={"key_columns": {"mgra", "age_group", "sex", "ethnicity"}},
            negative={},
            null={},
        )


def _insert_ase(ase_outputs: dict[str, pd.DataFrame]) -> None:
    """Insert age/sex/ethnicity population by type to database."""
    for pop_type, output in ase_outputs.items():
        logger.info("Loading Estimates for " + pop_type)

        # Convert the DataFrame to a Polars DataFrame
        # Polars used solely for write to CSV performance
        pl_df = pl.from_pandas(
            output[
                [
                    "run_id",
                    "year",
                    "mgra",
                    "pop_type",
                    "age_group",
                    "sex",
                    "ethnicity",
                    "value",
                ]
            ],
            include_index=False,
        )

        # Write the DataFrame to a CSV file
        pl_df.write_csv(
            utils.BULK_INSERT_STAGING / (pop_type + ".txt"),
            include_header=False,
            separator="|",
            quote_style="never",
        )

        # Bulk insert the CSV file into the production database
        with utils.ESTIMATES_ENGINE.connect() as con:
            fp = (utils.BULK_INSERT_STAGING / (pop_type + ".txt")).as_posix()
            query = sql.text(
                f"""
                    BULK INSERT [outputs].[ase]
                    FROM '{fp}'
                    WITH (
                        TABLOCK,
                        MAXERRORS=0,
                        FIELDTERMINATOR = '|',
                        ROWTERMINATOR = '0x0A',
                        CHECK_CONSTRAINTS
                    )
                """
            )
            con.execute(query)
            con.commit()

        # Remove the temporary CSV file
        (utils.BULK_INSERT_STAGING / (pop_type + ".txt")).unlink()
