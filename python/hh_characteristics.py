# Container for the Household Characteristics module. See the Estimates-Program wiki
# page for more details:
# https://github.com/SANDAG/Estimates-Program/wiki/Household-Characteristics

import pandas as pd
import sqlalchemy as sql

import python.utils as utils
import python.tests as tests


def run_hh_characteristics(year: int) -> None:
    """Orchestrator function to calculate and insert household characteristics.

    The exact household characteristics created are:
    1. Households split by household income category
    2. Households split by number of people in each household

    Both characteristics are generated by applying ACS data to MGRA level households,
    which are created by the HS/HH module.

    Functionality is segmented into functions for code encapsulation. The following are
    used for households split by income category:
        _get_hh_income_inputs - Get MGRA households and ACS tract distributions for
            income
        _validate_hh_income_inputs - Validate the hh income input data
        _create_hh_income - Calculate the hh income, control to MGRA households
        _validate_hh_income_outputs - Validate the hh income output data
        _insert_hh_income - Insert hh income and tract level income distributions to
            database

    The following functions are used for households split by size
        _get_hh_size_inputs - Get MGRA households, MGRA household population, and ACS
            tract distributions for size
        _validate_hh_size_inputs - Validate the hh size input data
        _create_hh_size - Calculate the hh size, control to MGRA households and MGRA
            household population
        _validate_hh_size_outputs - Validate the hh size output data
        _insert_hh_size - Insert hh size and tract level size distributions to database

    Args:
        year (int): estimates year
    """
    # Start with household income
    hh_income_inputs = _get_hh_income_inputs(year)
    _validate_hh_income_inputs(year, hh_income_inputs)

    hh_income_outputs = _create_hh_income(hh_income_inputs)
    _validate_hh_income_outputs(hh_income_outputs)

    _insert_hh_income(hh_income_inputs, hh_income_outputs)

    # Then do households by size
    hh_size_inputs = _get_hh_size_inputs(year)
    _validate_hh_size_inputs(year, hh_size_inputs)

    hh_size_outputs = _create_hh_size(hh_size_inputs)
    _validate_hh_size_outputs(hh_size_outputs)

    _insert_hh_size(hh_size_inputs, hh_size_outputs)


def _get_hh_income_inputs(year: int) -> dict[str, pd.DataFrame]:
    """Get households and various tract level datas"""
    with utils.ESTIMATES_ENGINE.connect() as con:
        # Store results here
        hh_income_inputs = {}

        # Get MGRA level households. Note we re-use the SQL script from the 'Population
        # by Type' module
        with open(utils.SQL_FOLDER / "pop_type" / "get_mgra_hh.sql") as file:
            hh_income_inputs["hh"] = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                    "mgra_version": utils.MGRA_VERSION,
                },
            ).drop(columns=["city"])

        # Tract level household income distributions
        with open(
            utils.SQL_FOLDER / "hh_characteristics" / "get_tract_controls_hh_income.sql"
        ) as file:
            hh_income_inputs["hh_income_tract_controls"] = utils.read_sql_query_acs(
                sql=sql.text(file.read()),
                con=con,
                params={"run_id": utils.RUN_ID, "year": year},
            )

    return hh_income_inputs


def _get_hh_size_inputs(year: int) -> dict[str, pd.DataFrame]:
    """Get households and various tract level datas"""
    with utils.ESTIMATES_ENGINE.connect() as con:
        # Store results here
        hh_char_inputs = {}

        # Get MGRA level households. Note we re-use the SQL script from the 'Population
        # by Type' module
        with open(utils.SQL_FOLDER / "pop_type" / "get_mgra_hh.sql") as file:
            hh_char_inputs["hh"] = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=con,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                    "mgra_version": utils.MGRA_VERSION,
                },
            ).drop(columns=["city"])

        # Tract level households by household size distributions
        with open(
            utils.SQL_FOLDER
            / "hh_characteristics"
            / "get_tract_controls_hh_by_size.sql"
        ) as file:
            hh_char_inputs["hhs_tract_controls"] = utils.read_sql_query_acs(
                sql=sql.text(file.read()),
                con=con,
                params={"run_id": utils.RUN_ID, "year": year},
            )

        # MGRA level household size controls
        with open(
            utils.SQL_FOLDER / "hh_characteristics" / "get_mgra_controls_hh_by_size.sql"
        ) as file:
            hh_char_inputs["hhs_mgra_controls"] = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=con,
                params={"run_id": utils.RUN_ID, "year": year},
            )

    return hh_char_inputs


def _validate_hh_income_inputs(
    year: int, hh_char_inputs: dict[str, pd.DataFrame]
) -> None:
    """Validate the household characteristics input data"""
    tests.validate_data(
        "MGRA households",
        hh_char_inputs["hh"],
        row_count={"key_columns": {"mgra"}},
        negative={},
        null={},
    )
    tests.validate_data(
        "Tract household income distribution",
        hh_char_inputs["hh_income_tract_controls"],
        row_count={"key_columns": {"tract", "income_category"}, "year": year},
        negative={},
        null={},
    )


def _validate_hh_size_inputs(
    year: int, hh_size_inputs: dict[str, pd.DataFrame]
) -> None:
    """Validate the household characteristics input data"""
    tests.validate_data(
        "MGRA households",
        hh_size_inputs["hh"],
        row_count={"key_columns": {"mgra"}},
        negative={},
        null={},
    )
    tests.validate_data(
        "Tract households by household size distribution",
        hh_size_inputs["hhs_tract_controls"],
        row_count={"key_columns": {"tract", "household_size"}, "year": year},
        negative={},
        null={},
    )
    tests.validate_data(
        "MGRA households by household size controls",
        hh_size_inputs["hhs_mgra_controls"],
        row_count={"key_columns": {"mgra"}},
        negative={},
        null={},
    )


def _create_hh_income(
    hh_income_inputs: dict[str, pd.DataFrame],
) -> dict[str, pd.DataFrame]:
    """Code to compute MGRA household income"""
    hh = hh_income_inputs["hh"]
    tract_income_dist = hh_income_inputs["hh_income_tract_controls"]

    # Combine the total households in each MGRA with the distribution of households by
    # income
    hh_income = (
        hh.merge(tract_income_dist, on=["run_id", "year", "tract"], how="left")
        .assign(hh=lambda df: df["hh"] * df["value"])
        .drop(columns=["tract", "value"])
    )

    # Control each MGRA so households by household income exactly matches the total
    # households
    integerized_groups = []
    for _, group in hh_income.groupby("mgra"):
        group["hh"] = utils.integerize_1d(group["hh"])
        integerized_groups.append(group)
    hh_income = pd.concat(integerized_groups)

    return {"hh_income": hh_income}


def _create_hh_size(
    hh_size_inputs: dict[str, pd.DataFrame],
) -> dict[str, pd.DataFrame]:
    """Code to compute MGRA households by size

    Similar to how income works, this function takes MGRA households, applies tract
    level rates, then integerizes the data. But additionally, we control to MGRA hhp.
    This is because the distribution of households by household size implies some
    minimum and maximum household population.

    For example, if we had 10 households of size one, 10 households of size two, ...,
    10 households of size 7+, the minimum amount of household population would be 1*10
    + 2*20 + ... + 7*10 = 280. On the flip side, the maximum amount of household
    population, assuming the 7+ category all actually average 11 people, would be 1*10
    + 2*20 + ... + 11*10 = 320. The actual amount of household population in this MGRA
    must be between these two values

    To make this adjustment, we basically move singular households up or down a size
    depending on the direction of adjustment needed. If the actual hhp is more than the
    max implied hhp, then households are shifted up. We first do HHS1 --> HHS2, then
    HHS2 --> 3, ..., HHS6 --> HHS7, HHS1 --> HHS2. This is repeated until the max
    implied hhp equals the actual hhp.

    If the actual hhp is less than the min implied hhp, we do the reverse process until
    the min implied hhp equals the actual hhp. In other words, we do HHS7 --> HHS6,
    then HHS6 --> HHS5, ..., HHS2 --> HHS1, HHS7 --> HHS6.
    """
    hh = hh_size_inputs["hh"]
    tract_hhs_dist = hh_size_inputs["hhs_tract_controls"]
    mgra_controls = hh_size_inputs["hhs_mgra_controls"]

    # Combine the total households in each MGRA with the distribution of households by
    # size
    hh_size = (
        hh.merge(tract_hhs_dist, on=["run_id", "year", "tract"], how="left")
        .assign(hh=lambda df: df["hh"] * df["value"])
        .drop(columns=["tract", "value"])
    )

    # Control each MGRA so households by size exactly match total households
    integerized_groups = []
    for _, group in hh_size.groupby("mgra"):
        group["hh"] = utils.integerize_1d(group["hh"])
        integerized_groups.append(group)
    hh_size = pd.concat(integerized_groups)

    # Control each MGRA to align with household population
    controlled_groups = []
    for mgra, group in hh_size.groupby("mgra"):
        control = mgra_controls[mgra_controls["mgra"] == mgra]
        hhp_total = control["hhp_total"].values[0]
        hhp_over_14 = control["hhp_over_14"].values[0]

        # Compute the minimum and maximum implied hhp from the hhs distribution. The
        # maximum assumes that every household in the 7+ category is of size 11, which
        # is what we get from looking at the San Diego region PUMS data. See GithHub
        # for more info:
        # https://github.com/SANDAG/Estimates-Program/issues/112
        n_people_in_7_plus = 11
        min_implied_hhp = (group["hh"] * group["household_size"]).sum()
        max_implied_hhp = (
            group["hh"] * group["household_size"].replace(7, n_people_in_7_plus)
        ).sum()

        # If the maximum implied hhp is smaller than the actual hhp, then we need to
        # shift some households from smaller sizes to larger sizes. Specifically, we
        # will shift one household from 1-->2, 2-->3, 6-->7+, 1-->2, etc. until
        # satisfied
        if max_implied_hhp < hhp_total:
            size_to_change = 1
            while max_implied_hhp < hhp_total:
                if group[group["household_size"] == size_to_change]["hh"].values[0] > 0:
                    group.loc[group["household_size"] == size_to_change, "hh"] -= 1
                    group.loc[group["household_size"] == size_to_change + 1, "hh"] += 1
                    max_implied_hhp += 1
                    if size_to_change == 6:
                        max_implied_hhp += n_people_in_7_plus - 7
                # Increase the size by one, but keep it in the inclusive range 1-6
                size_to_change = (size_to_change % 6) + 1

        # If the minimum implied hhp is greater than the actual hhp, then we need to
        # shift some households from larger sizes to smaller sizes
        if min_implied_hhp > hhp_total:
            size_to_change = 7
            while min_implied_hhp > hhp_total:
                if group[group["household_size"] == size_to_change]["hh"].values[0] > 0:
                    group.loc[group["household_size"] == size_to_change, "hh"] -= 1
                    group.loc[group["household_size"] == size_to_change - 1, "hh"] += 1
                    min_implied_hhp -= 1
                # Decrease size by one, but keep it in the inclusive range 2-7
                size_to_change = (size_to_change - 3) % 6 + 2

        # TODO: Log a warning if the number of households in HHS1 exceeds the hhp over
        # 14 in this MGRA. We cannot fix this here as this is most likely an ASE error,
        # not a hh characteristics error

        # Store the controlled group
        controlled_groups.append(group)

    return {"hh_size": pd.concat(controlled_groups)}


def _validate_hh_income_outputs(hh_income_outputs: dict[str, pd.DataFrame]) -> None:
    """Validate the household income output data"""
    tests.validate_data(
        "MGRA Household Income",
        hh_income_outputs["hh_income"],
        row_count={"key_columns": {"mgra", "income_category"}},
        negative={},
        null={},
    )


def _validate_hh_size_outputs(hh_size_outputs: dict[str, pd.DataFrame]) -> None:
    """Validate the household size output data"""
    tests.validate_data(
        "MGRA Households by Size",
        hh_size_outputs["hh_size"],
        row_count={"key_columns": {"mgra", "household_size"}},
        negative={},
        null={},
    )


def _insert_hh_income(
    hh_income_inputs: dict[str, pd.DataFrame],
    hh_income_outputs: dict[str, pd.DataFrame],
) -> None:
    """Insert hh characteristics and tract level controls to database"""
    with utils.ESTIMATES_ENGINE.connect() as con:
        hh_income_inputs["hh_income_tract_controls"][
            ["run_id", "year", "tract", "income_category", "value"]
        ].rename(columns={"income_category": "metric"}).assign(
            metric=lambda df: "Income Category - " + df["metric"]
        ).to_sql(
            schema="inputs",
            name="controls_tract",
            if_exists="append",
            con=con,
            index=False,
        )

        hh_income_outputs["hh_income"][
            ["run_id", "year", "mgra", "income_category", "hh"]
        ].rename(columns={"income_category": "metric", "hh": "value"}).assign(
            metric=lambda df: "Income Category - " + df["metric"]
        ).to_sql(
            schema="outputs",
            name="hh_characteristics",
            if_exists="append",
            con=con,
            index=False,
        )


def _insert_hh_size(
    hh_size_inputs: dict[str, pd.DataFrame], hh_size_outputs: dict[str, pd.DataFrame]
) -> None:
    """Insert hh characteristics and tract level controls to database"""
    with utils.ESTIMATES_ENGINE.connect() as con:
        hh_size_inputs["hhs_tract_controls"].rename(
            columns={"household_size": "metric"}
        ).assign(
            metric=lambda df: "Household Size - "
            + df["metric"].astype(str).replace("7", "7+")
        ).to_sql(
            schema="inputs",
            name="controls_tract",
            if_exists="append",
            con=con,
            index=False,
        )

        hh_size_outputs["hh_size"][
            ["run_id", "year", "mgra", "household_size", "hh"]
        ].rename(columns={"household_size": "metric", "hh": "value"}).assign(
            metric=lambda df: "Household Size - "
            + df["metric"].astype(str).replace("7", "7+")
        ).to_sql(
            schema="outputs",
            name="hh_characteristics",
            if_exists="append",
            con=con,
            index=False,
        )
