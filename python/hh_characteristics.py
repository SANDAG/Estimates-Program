# Container for the Household Characteristics module. See the Estimates-Program wiki
# page for more details:
# https://github.com/SANDAG/Estimates-Program/wiki/Household-Characteristics

import numpy as np
import pandas as pd
import sqlalchemy as sql

import python.utils as utils
import python.tests as tests


def run_hh_characteristics(year: int) -> None:
    """Orchestrator function to calculate and insert household characteristics.

    The exact household characteristics created are:
    1. Households split by household income category
    2. Households split by number of people in each household

    Both characteristics are generated by applying ACS data to MGRA level households,
    which are created by the HS/HH module.

    Functionality is segmented into functions for code encapsulation:
        _get_hh_char_inputs - Get MGRA households (which are used for both
            characteristics) and ACS tract rates
        _validate_hh_char_inputs - Validate the hh characteristics input data
        _create_hh_char - Calculate the hh characteristics listed above
        _validate_hh_char_outputs - Validate the hh characteristics output data
        _insert_hh_char - Insert hh characteristics and tract level controls to database

    Args:
        year (int): estimates year
    """
    hh_char_inputs = _get_hh_char_inputs(year)
    _validate_hh_char_inputs(year, hh_char_inputs)

    hh_char_outputs = _create_hh_char(hh_char_inputs)
    _validate_hh_char_outputs(hh_char_outputs)

    _insert_hh_char(hh_char_inputs, hh_char_outputs)


def _get_hh_char_inputs(year: int) -> dict[str, pd.DataFrame]:
    """Get households and various tract level datas"""
    with utils.ESTIMATES_ENGINE.connect() as conn:
        # Store results here
        hh_char_inputs = {}

        # Get MGRA level households. Note we re-use the SQL script from the 'Population
        # by Type' module
        with open(utils.SQL_FOLDER / "pop_type" / "get_mgra_hh.sql") as file:
            hh_char_inputs["hh"] = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={
                    "run_id": utils.RUN_ID,
                    "year": year,
                    "mgra_version": utils.MGRA_VERSION,
                },
            ).drop(columns=["city"])

        # Tract level household income distributions
        with open(
            utils.SQL_FOLDER / "hh_characteristics" / "get_tract_controls_hh_income.sql"
        ) as file:
            hh_char_inputs["hh_income_tract_controls"] = pd.read_sql_query(
                sql=sql.text(file.read()),
                con=conn,
                params={"run_id": utils.RUN_ID, "year": year},
            )

    return hh_char_inputs


def _validate_hh_char_inputs(
    year: int, hh_char_inputs: dict[str, pd.DataFrame]
) -> None:
    """Validate the household characteristics input data"""
    tests.validate_data(
        "MGRA households",
        hh_char_inputs["hh"],
        row_count={"key_columns": {"mgra"}},
        negative={},
        null={},
    )
    tests.validate_data(
        "Tract household income distribution",
        hh_char_inputs["hh_income_tract_controls"],
        row_count={"key_columns": {"tract", "income_category"}, "year": year},
        negative={},
        null={},
    )


def _create_hh_char(hh_char_inputs: dict[str, pd.DataFrame]) -> dict[str, pd.DataFrame]:
    """Calculate the various household characteristics by MGRA."""
    hh = hh_char_inputs["hh"]
    tract_income_dist = hh_char_inputs["hh_income_tract_controls"]

    # Combine the total households in each MGRA with the distribution of households by
    # income
    hh_income = (
        hh.merge(tract_income_dist, on=["run_id", "year", "tract"], how="left")
        .assign(hh=lambda df: df["hh"] * df["value"])
        .drop(columns=["tract", "value"])
    )

    # Control each MGRA so households by household income exactly matches the total
    # households
    integerized_groups = []
    for _, group in hh_income.groupby("mgra"):
        group["hh"] = utils.integerize_1d(group["hh"])
        integerized_groups.append(group)
    hh_income = pd.concat(integerized_groups)

    return {"hh_income": hh_income}


def _validate_hh_char_outputs(hh_char_outputs: dict[str, pd.DataFrame]) -> None:
    """Validate the household characteristics data"""
    tests.validate_data(
        "MGRA Households",
        hh_char_outputs["hh_income"],
        row_count={"key_columns": {"mgra", "income_category"}},
        negative={},
        null={},
    )
    pass


def _insert_hh_char(
    hh_char_inputs: dict[str, pd.DataFrame], hh_char_outputs: dict[str, pd.DataFrame]
) -> None:
    """Insert hh characteristics and tract level controls to database"""
    with utils.ESTIMATES_ENGINE.connect() as conn:
        hh_char_inputs["hh_income_tract_controls"][
            ["run_id", "year", "tract", "income_category", "value"]
        ].rename(columns={"income_category": "metric"}).assign(
            metric=lambda df: "Income Category - " + df["metric"]
        ).to_sql(
            schema="inputs",
            name="controls_tract",
            if_exists="append",
            con=conn,
            index=False,
        )

        hh_char_outputs["hh_income"][
            ["run_id", "year", "mgra", "income_category", "hh"]
        ].rename(columns={"income_category": "metric", "hh": "value"}).assign(
            metric=lambda df: "Income Category - " + df["metric"]
        ).to_sql(
            schema="outputs",
            name="hh_characteristics",
            if_exists="append",
            con=conn,
            index=False,
        )
